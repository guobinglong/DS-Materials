我们将方法分为两大类：平均效应（ATE）与异质效应（CATE / Uplift）

平均处理效应（ATE）估计----“整体有没有效”条件     

平均处理效应（CATE） / Uplift Modeling —— “对谁有效？怎么个性化？

# 1. 倾向得分匹配（Propensity Score Matching, PSM）
通过“找相似的人”来模拟随机实验：给每个接受干预的人，匹配一个特征相似但未接受干预的对照者。

举例：

想象你要评估“上重点高中是否提高高考成绩”。问题：上重点高中的学生本来成绩就好（混杂偏误）。PSM 做法：为每个上重点高中的学生，找一个成绩、家庭背景、初中排名等都差不多但没上重点高中的学生做“替身”。然后比较这两组人的高考成绩差异 → 这就是因果效应。

# 2. 双重差分法（Difference-in-Differences, DID）
利用“处理组 vs 对照组” + “政策前后”的双重差异，剔除时间趋势和组别固有差异。

举例： 

评估“某省最低工资上调是否减少就业”：仅看该省：就业下降？可能是经济下行（时间趋势干扰）。仅看其他省：就业稳定？但各省基础不同（组别差异）。DID 做法：DID = (处理省/后 - 处理省/前) - （对照省/后 - 对照省/前）。→ 相当于“处理省的变化减去对照省的变化”。

# 3. 工具变量法（Instrumental Variables, IV）
找一个“只通过影响干预来影响结果”的外生变量，绕过混杂偏误。

举例：

研究“教育年限是否提高收入”：问题：聪明人既多读书又赚得多（能力是混杂因子）。IV 做法：用“出生季度”作为工具变量（美国早年义务教育按年龄 cutoff，Q4 出生的孩子上学晚，平均少读半年书）。出生季度 → 只影响教育年限，不影响收入（除了通过教育）→ 是好工具！

 # 4. 断点回归（Regression Discontinuity Design, RDD）
 在某个“分数线”附近，规则导致干预突然变化，利用这种“局部随机性”识别因果。

 举例：

 奖学金规则：高考 ≥ 600 分 → 发 1 万元。599 分 vs 600 分的学生几乎一样（连续性假设）。但 600 分的拿了钱，599 分的没拿 → 比较这两群人的大学表现，就是奖学金的因果效应。

 # 5. 合成控制法（Synthetic Control Method, SCM）
 为“唯一处理单元”（如一个州）构造一个“虚拟对照组”，由多个未处理单元加权合成。

 举例：

 加州实施控烟法，想评估对香烟销量的影响。问题：没有哪个州和加州完全一样。SCM 做法：用纽约、德州、佛罗里达等州的加权组合（如 0.3×NY + 0.5×TX + 0.2×FL）构造一个“合成加州”。这个合成加州在政策前与真实加州走势高度一致。政策后，两者差异 = 控制法效果。

 # 6. 因果树（Causal Tree）/因果森林（Causal Forest）
修改决策树的分裂规则，使其在每个子节点最大化因果效应的异质性，而非预测精度。因果森林（Causal Forest） 是其集成版本，通过 bagging 提升稳定性。

 举例：
 
普通决策树：问“哪个特征最能预测用户是否购买？”。因果树：问“哪个特征最能区分‘发券有效’和‘发券无效’的用户？”
 
 
























 
